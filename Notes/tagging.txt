

================================================
File: src/the_aichemist_codex/backend/tagging/__init__.py
================================================
"""
Tagging module for intelligent file organization.

This module provides functionality for managing file tags, including
automatic tag suggestion, hierarchical tag organization, and tag-based
file retrieval.
"""

from .hierarchy import TagHierarchy
from .manager import TagManager

__all__ = ["TagManager", "TagHierarchy"]



================================================
File: src/the_aichemist_codex/backend/tagging/classifier.py
================================================
"""
Tag classification module for automatic file tagging.

This module provides the TagClassifier class, which is responsible for
training and applying machine learning models to automatically tag files
based on their content and metadata.
"""

import json
import logging
import os
import pickle
from datetime import datetime
from pathlib import Path
from typing import Any

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.multioutput import MultiOutputClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.svm import LinearSVC

from the_aichemist_codex.backend.file_reader.file_metadata import FileMetadata

logger = logging.getLogger(__name__)


class TagClassifier:
    """
    Machine learning classifier for automatic file tagging.

    This class provides methods for training and applying machine learning
    models to automatically tag files based on their content and metadata.
    """

    DEFAULT_CONFIDENCE_THRESHOLD = 0.6

    def __init__(self, model_dir: Path):
        """
        Initialize the TagClassifier with a model directory.

        Args:
            model_dir: Directory to store model files
        """
        self.model_dir = model_dir
        self.model_path = self.model_dir / "tag_classifier.pkl"
        self.metadata_path = self.model_dir / "tag_classifier_metadata.json"

        self.pipeline: Pipeline | None = None
        self.mlb: MultiLabelBinarizer | None = None
        self.feature_names: np.ndarray | None = None
        self.tag_names: list[str] = []
        self.training_metadata: dict[str, Any] = {}

        # Initialize the default model
        self._initialize_default_model()

    def _initialize_default_model(self) -> None:
        """Initialize the default model pipeline."""
        # Create a basic pipeline with TF-IDF and SVM
        self.pipeline = Pipeline(
            [
                ("vectorizer", TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),
                (
                    "classifier",
                    MultiOutputClassifier(
                        LinearSVC(C=1.0, class_weight="balanced", max_iter=10000)
                    ),
                ),
            ]
        )

        # Initialize MultiLabelBinarizer for tag encoding
        self.mlb = MultiLabelBinarizer()

        # Initialize empty tag set
        self.tag_names = []

    async def load_model(self) -> bool:
        """
        Load a trained model from disk.

        Returns:
            bool: True if a model was loaded, False otherwise
        """
        try:
            # Ensure model directory exists
            self.model_dir.mkdir(parents=True, exist_ok=True)

            # Check if model file exists
            if not self.model_path.exists():
                logger.info("No trained model found, using default model")
                return False

            # Load the model
            with open(self.model_path, "rb") as f:
                model_data = pickle.load(f)
                self.pipeline = model_data["pipeline"]
                self.mlb = model_data["mlb"]
                self.feature_names = model_data.get("feature_names")
                self.tag_names = model_data.get("tag_names", [])

            # Load metadata if available
            if self.metadata_path.exists():
                with open(self.metadata_path) as f:
                    self.training_metadata = json.load(f)

            logger.info(f"Loaded tag classifier model with {len(self.tag_names)} tags")
            return True

        except Exception as e:
            logger.error(f"Failed to load tag classifier model: {e}")
            self._initialize_default_model()
            return False

    async def save_model(self) -> bool:
        """
        Save the current model to disk.

        Returns:
            bool: True if the model was saved successfully, False otherwise
        """
        try:
            # Ensure model directory exists
            os.makedirs(self.model_dir, exist_ok=True)

            # Save the model
            model_data = {
                "pipeline": self.pipeline,
                "mlb": self.mlb,
                "feature_names": self.feature_names,
            }

            with open(self.model_path, "wb") as f:
                pickle.dump(model_data, f)

            # Update training metadata
            self.training_metadata.update(
                {
                    "last_updated": datetime.now().isoformat(),
                    "tag_names": self.tag_names,
                    "num_tags": len(self.tag_names),
                }
            )

            # Save metadata
            with open(self.metadata_path, "w") as f:
                json.dump(self.training_metadata, f, indent=2)

            logger.info(f"Saved tag classifier model with {len(self.tag_names)} tags")
            return True

        except Exception as e:
            logger.error(f"Error saving tag classifier model: {e}")
            return False

    def _extract_features(self, file_metadata: FileMetadata) -> str:
        """
        Extract features from file metadata for classification.

        Args:
            file_metadata: FileMetadata object

        Returns:
            str: Text features extracted from metadata
        """
        features = []

        # Add filename and extension
        if file_metadata.path:
            path = Path(file_metadata.path)
            features.append(path.name)
            if path.suffix:
                features.append(path.suffix.lstrip("."))

        # Add MIME type
        if file_metadata.mime_type:
            features.append(file_metadata.mime_type)

        # Add extracted content
        if file_metadata.preview:
            features.append(file_metadata.preview[:5000])  # Limit preview size

        # Add topics if available
        if hasattr(file_metadata, "topics") and file_metadata.topics:
            for topic_dict in file_metadata.topics:
                for topic, score in topic_dict.items():
                    features.append(f"topic:{topic}")

        # Add keywords if available
        if hasattr(file_metadata, "keywords") and file_metadata.keywords:
            for keyword in file_metadata.keywords:
                features.append(f"keyword:{keyword}")

        # Add entities if available
        if hasattr(file_metadata, "entities") and file_metadata.entities:
            for entity_type, entities in file_metadata.entities.items():
                for entity in entities:
                    features.append(f"entity:{entity_type}:{entity}")

        # Add language if available
        if hasattr(file_metadata, "language") and file_metadata.language:
            features.append(f"lang:{file_metadata.language}")

        # Add content type if available
        if hasattr(file_metadata, "content_type") and file_metadata.content_type:
            features.append(f"content_type:{file_metadata.content_type}")

        # Join all features
        return " ".join(str(feature) for feature in features if feature)

    def _get_tag_scores(self, file_metadata: FileMetadata) -> list[tuple[str, float]]:
        """
        Get confidence scores for all tags for a file.

        Args:
            file_metadata: File metadata

        Returns:
            List[Tuple[str, float]]: List of (tag_name, confidence) tuples
        """
        if not self.pipeline or not self.mlb or not self.tag_names:
            logger.warning("Model not initialized, cannot get tag scores")
            return []

        # Pipeline must not be None at this point
        pipeline = self.pipeline
        if pipeline is None:  # This is for type checking only
            return []

        try:
            # Extract features
            features = self._extract_features(file_metadata)
            if not features:
                logger.warning(f"No features extracted from file: {file_metadata.path}")
                return []

            # Convert to vector
            X = [features]

            # Get classifier from pipeline
            classifier = pipeline.named_steps["classifier"]

            # Transform text to TF-IDF
            X_tfidf = pipeline.named_steps["vectorizer"].transform(X)

            # For each classifier, get decision function scores
            tag_scores = []

            for i, estimator in enumerate(classifier.estimators_):
                if i < len(self.tag_names):
                    if hasattr(estimator, "decision_function"):
                        # Get decision score
                        score = estimator.decision_function(X_tfidf)[0]

                        # Convert to probability-like score (0-1)
                        # Using sigmoid function: 1 / (1 + exp(-x))
                        confidence = 1 / (1 + np.exp(-score))

                        tag_scores.append((self.tag_names[i], float(confidence)))
                    else:
                        # If no decision function, use predict_proba
                        proba = estimator.predict_proba(X_tfidf)[0][1]
                        tag_scores.append((self.tag_names[i], float(proba)))

            # Sort by confidence
            tag_scores.sort(key=lambda x: x[1], reverse=True)
            return tag_scores

        except Exception as e:
            logger.error(f"Error getting tag scores: {e}")
            return []

    async def classify(
        self,
        file_metadata: FileMetadata,
        confidence_threshold: float = DEFAULT_CONFIDENCE_THRESHOLD,
    ) -> list[tuple[str, float]]:
        """
        Classify a file and suggest tags with confidence scores.

        Args:
            file_metadata: FileMetadata object
            confidence_threshold: Minimum confidence threshold for tag suggestions

        Returns:
            List[Tuple[str, float]]: List of (tag_name, confidence) tuples
        """
        # Check if model is loaded
        if self.pipeline is None or self.mlb is None or not self.tag_names:
            await self.load_model()
            if not self.tag_names:
                logger.warning("No tags available for classification")
                return []

        # At this point, ensure pipeline is not None
        pipeline = self.pipeline
        if pipeline is None:  # This is for type checking only
            return []

        try:
            # Extract features
            features = self._extract_features(file_metadata)
            if not features:
                logger.warning(f"No features extracted from file: {file_metadata.path}")
                return []

            # Convert to vector
            X = [features]

            # Get classifier from pipeline
            classifier = pipeline.named_steps["classifier"]

            # Transform text to TF-IDF
            X_tfidf = pipeline.named_steps["vectorizer"].transform(X)

            # For each classifier, get decision function scores
            tag_scores = []

            for i, estimator in enumerate(classifier.estimators_):
                if i < len(self.tag_names):
                    if hasattr(estimator, "decision_function"):
                        # Get decision score
                        score = estimator.decision_function(X_tfidf)[0]

                        # Convert to probability-like confidence (sigmoid)
                        confidence = 1 / (1 + np.exp(-score))

                        if confidence >= confidence_threshold:
                            tag_scores.append((self.tag_names[i], float(confidence)))

            # Sort by confidence
            tag_scores.sort(key=lambda x: x[1], reverse=True)

            return tag_scores

        except Exception as e:
            logger.error(f"Error classifying file {file_metadata.path}: {e}")
            return []

    async def train(
        self,
        training_data: list[tuple[FileMetadata, list[str]]],
        test_size: float = 0.2,
        random_state: int = 42,
    ) -> dict[str, Any]:
        """
        Train the classifier with labeled examples.

        Args:
            training_data: List of (file_metadata, tags) tuples
            test_size: Portion of data to use for testing
            random_state: Random seed for reproducibility

        Returns:
            Dict[str, Any]: Training results with metrics

        Raises:
            ValueError: If training data is empty
        """
        if not training_data:
            raise ValueError("Training data cannot be empty")

        # Initialize components if needed
        if self.pipeline is None:
            self._initialize_default_model()

        if self.mlb is None:
            self.mlb = MultiLabelBinarizer()

        # Ensure we have valid pipeline and mlb objects
        pipeline = self.pipeline
        mlb = self.mlb
        if pipeline is None or mlb is None:
            logger.error("Failed to initialize model components")
            raise RuntimeError("Model components could not be initialized")

        try:
            # Extract features and labels
            X = []
            y = []

            for metadata, tags in training_data:
                features = self._extract_features(metadata)
                if features:
                    X.append(features)
                    y.append(tags)

            if not X or not y:
                raise ValueError(
                    "No valid features or tags extracted from training data"
                )

            # Fit the binarizer on all tags
            y_bin = mlb.fit_transform(y)
            self.tag_names = list(mlb.classes_)

            # Split data into train and test sets
            X_train, X_test, y_train, y_test = train_test_split(
                X, y_bin, test_size=test_size, random_state=random_state
            )

            # Train the model
            pipeline.fit(X_train, y_train)

            # Get feature names for introspection
            self.feature_names = pipeline.named_steps[
                "vectorizer"
            ].get_feature_names_out()

            # Evaluate on test set
            accuracy = pipeline.score(X_test, y_test)

            # Record training metadata
            self.training_metadata = {
                "num_samples": len(X),
                "num_tags": len(self.tag_names),
                "tag_names": self.tag_names,
                "accuracy": accuracy,
                "training_date": datetime.now().isoformat(),
                "test_size": test_size,
            }

            # Save the model
            await self.save_model()

            logger.info(
                f"Trained tag classifier on {len(X)} samples with {len(self.tag_names)} tags. Accuracy: {accuracy:.4f}"
            )

            return self.training_metadata

        except Exception as e:
            logger.error(f"Error training tag classifier: {e}")
            raise

    async def get_tag_features(
        self, tag_name: str, top_n: int = 10
    ) -> list[tuple[str, float]]:
        """
        Get the most important features for a tag.

        Args:
            tag_name: Name of the tag
            top_n: Number of top features to return

        Returns:
            List[Tuple[str, float]]: List of (feature, importance) tuples
        """
        if not self.pipeline or not self.mlb or not self.feature_names:
            await self.load_model()
            if not self.tag_names or not self.feature_names:
                return []

        # Make sure pipeline and feature_names are not None
        pipeline = self.pipeline
        feature_names = self.feature_names
        if pipeline is None or feature_names is None:
            logger.warning("Pipeline or feature_names not available")
            return []

        try:
            # Get tag index
            if tag_name not in self.tag_names:
                return []

            tag_idx = self.tag_names.index(tag_name)

            # Get coefficients for the tag
            classifier = pipeline.named_steps["classifier"]
            if tag_idx >= len(classifier.estimators_):
                return []

            estimator = classifier.estimators_[tag_idx]
            coefficients = estimator.coef_[0]

            # Pair features with coefficients
            feature_importance = [
                (feature, coef)
                for feature, coef in zip(feature_names, coefficients, strict=False)
            ]

            # Sort by absolute importance
            feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)

            # Return top features
            return feature_importance[:top_n]

        except Exception as e:
            logger.error(f"Error finding important features for {tag_name}: {e}")
            return []

    async def get_model_info(self) -> dict[str, Any]:
        """
        Get information about the current model.

        Returns:
            Dict[str, Any]: Model information and metadata
        """
        # Try to load the model if not loaded
        if not self.training_metadata:
            await self.load_model()

        return {
            **self.training_metadata,
            "model_path": str(self.model_path),
            "is_loaded": self.pipeline is not None and self.mlb is not None,
            "num_features": (
                len(self.feature_names) if self.feature_names is not None else 0
            ),
        }

    async def get_similar_tags(
        self, tag_name: str, top_n: int = 5
    ) -> list[tuple[str, float]]:
        """
        Find tags that are similar to the given tag based on model coefficients.

        Args:
            tag_name: Tag name
            top_n: Number of similar tags to return

        Returns:
            List[Tuple[str, float]]: List of (tag_name, similarity) tuples
        """
        if not self.pipeline or not self.mlb or not self.tag_names:
            await self.load_model()
            if not self.tag_names:
                return []

        # Ensure pipeline is not None
        pipeline = self.pipeline
        if pipeline is None:
            logger.warning("Pipeline not available")
            return []

        try:
            # Get tag index
            if tag_name not in self.tag_names:
                return []

            tag_idx = self.tag_names.index(tag_name)

            # Get coefficients for the tag
            classifier = pipeline.named_steps["classifier"]
            if tag_idx >= len(classifier.estimators_):
                return []

            reference_estimator = classifier.estimators_[tag_idx]
            reference_coefficients = reference_estimator.coef_[0]

            # Calculate cosine similarity with all other tags
            similarities = []

            for i, estimator in enumerate(classifier.estimators_):
                if i != tag_idx and i < len(self.tag_names):
                    coefficients = estimator.coef_[0]

                    # Calculate cosine similarity
                    dot_product = np.dot(reference_coefficients, coefficients)
                    norm_product = np.linalg.norm(
                        reference_coefficients
                    ) * np.linalg.norm(coefficients)
                    similarity = dot_product / norm_product if norm_product != 0 else 0

                    similarities.append((self.tag_names[i], float(similarity)))

            # Sort by similarity
            similarities.sort(key=lambda x: x[1], reverse=True)

            return similarities[:top_n]

        except Exception as e:
            logger.error(f"Error finding similar tags for {tag_name}: {e}")
            return []

    async def train_model(
        self,
        training_data: list[tuple[FileMetadata, list[str]]],
        test_size: float = 0.2,
        random_state: int = 42,
    ) -> dict[str, Any]:
        """
        Train the tag classifier on a dataset of file metadata and tags.

        Args:
            training_data: List of (file_metadata, tags) tuples
            test_size: Proportion of data to use for testing
            random_state: Random seed for reproducibility

        Returns:
            Dict[str, Any]: Training results and metrics

        Raises:
            ValueError: If training data is insufficient
        """
        if not training_data:
            raise ValueError("No training data provided")

        # Initialize components if not already done
        if self.pipeline is None:
            self._initialize_default_model()

        if self.mlb is None:
            self.mlb = MultiLabelBinarizer()

        # Ensure we have valid pipeline and mlb objects
        assert self.pipeline is not None, "Pipeline not initialized"
        assert self.mlb is not None, "MultiLabelBinarizer not initialized"

        try:
            # Extract features and labels
            X = []
            y = []

            for metadata, tags in training_data:
                features = self._extract_features(metadata)
                if features:
                    X.append(features)
                    y.append(tags)

            if not X or not y:
                raise ValueError(
                    "No valid features or tags extracted from training data"
                )

            # Fit the binarizer on all tags
            y_bin = self.mlb.fit_transform(y)
            self.tag_names = list(self.mlb.classes_)

            # Split data into train and test sets
            X_train, X_test, y_train, y_test = train_test_split(
                X, y_bin, test_size=test_size, random_state=random_state
            )

            # Train the model
            self.pipeline.fit(X_train, y_train)

            # Get feature names for introspection
            self.feature_names = self.pipeline.named_steps[
                "vectorizer"
            ].get_feature_names_out()

            # Evaluate on test set
            accuracy = self.pipeline.score(X_test, y_test)

            # Record training metadata
            self.training_metadata = {
                "num_samples": len(X),
                "num_tags": len(self.tag_names),
                "tag_names": self.tag_names,
                "accuracy": accuracy,
                "trained_at": datetime.now().isoformat(),
            }

            # Save the model
            await self.save_model()

            logger.info(
                f"Trained tag classifier on {len(X)} samples with {len(self.tag_names)} tags. Accuracy: {accuracy:.4f}"
            )

            return self.training_metadata

        except Exception as e:
            logger.error(f"Error training tag classifier: {e}")
            raise



================================================
File: src/the_aichemist_codex/backend/tagging/hierarchy.py
================================================
"""
Tag hierarchy management for organizing tags in a hierarchical structure.

This module provides the TagHierarchy class, which manages parent-child
relationships between tags, enabling more powerful organization and
categorization of files.
"""

import logging
import sqlite3
from typing import Any

logger = logging.getLogger(__name__)


class TagHierarchy:
    """
    Manages hierarchical relationships between tags.

    This class provides methods for creating, retrieving, and managing
    parent-child relationships between tags, enabling the organization
    of tags into a hierarchical structure.
    """

    def __init__(self, conn: sqlite3.Connection):
        """
        Initialize the tag hierarchy with a database connection.

        Args:
            conn: SQLite database connection
        """
        self.conn = conn

    def add_relationship(self, parent_id: int, child_id: int) -> bool:
        """
        Add a parent-child relationship between two tags.

        Args:
            parent_id: ID of the parent tag
            child_id: ID of the child tag

        Returns:
            bool: True if the relationship was added, False if it already exists
                 or would create a cycle

        Raises:
            sqlite3.IntegrityError: If the parent or child tag doesn't exist
        """
        # Check for potential cycles
        if self._would_create_cycle(parent_id, child_id):
            logger.warning(
                f"Cannot add relationship {parent_id} -> {child_id}: would create cycle"
            )
            return False

        try:
            cursor = self.conn.execute(
                "INSERT INTO tag_hierarchy (parent_id, child_id) VALUES (?, ?)",
                (parent_id, child_id),
            )
            self.conn.commit()
            added = cursor.rowcount > 0
            if added:
                logger.debug(
                    f"Added tag hierarchy relationship: {parent_id} -> {child_id}"
                )
            return added
        except sqlite3.IntegrityError as e:
            if "UNIQUE constraint failed" in str(e):
                logger.debug(f"Relationship already exists: {parent_id} -> {child_id}")
                return False
            logger.error(f"Error adding relationship {parent_id} -> {child_id}: {e}")
            raise

    def remove_relationship(self, parent_id: int, child_id: int) -> bool:
        """
        Remove a parent-child relationship between two tags.

        Args:
            parent_id: ID of the parent tag
            child_id: ID of the child tag

        Returns:
            bool: True if the relationship was removed, False if not found
        """
        cursor = self.conn.execute(
            "DELETE FROM tag_hierarchy WHERE parent_id = ? AND child_id = ?",
            (parent_id, child_id),
        )
        self.conn.commit()
        removed = cursor.rowcount > 0
        if removed:
            logger.debug(
                f"Removed tag hierarchy relationship: {parent_id} -> {child_id}"
            )
        return removed

    def get_parents(self, tag_id: int) -> list[dict[str, Any]]:
        """
        Get direct parent tags of a tag.

        Args:
            tag_id: Tag ID

        Returns:
            List[Dict[str, Any]]: List of parent tag data
        """
        cursor = self.conn.execute(
            """
            SELECT t.id, t.name, t.description
            FROM tag_hierarchy th
            JOIN tags t ON th.parent_id = t.id
            WHERE th.child_id = ?
            ORDER BY t.name
            """,
            (tag_id,),
        )
        return [dict(row) for row in cursor.fetchall()]

    def get_children(self, tag_id: int) -> list[dict[str, Any]]:
        """
        Get direct child tags of a tag.

        Args:
            tag_id: Tag ID

        Returns:
            List[Dict[str, Any]]: List of child tag data
        """
        cursor = self.conn.execute(
            """
            SELECT t.id, t.name, t.description
            FROM tag_hierarchy th
            JOIN tags t ON th.child_id = t.id
            WHERE th.parent_id = ?
            ORDER BY t.name
            """,
            (tag_id,),
        )
        return [dict(row) for row in cursor.fetchall()]

    def get_ancestors(self, tag_id: int) -> list[dict[str, Any]]:
        """
        Get all ancestor tags of a tag (recursive parents).

        Args:
            tag_id: Tag ID

        Returns:
            List[Dict[str, Any]]: List of ancestor tag data
        """
        # Use recursive CTE (Common Table Expression) to get all ancestors
        cursor = self.conn.execute(
            """
            WITH RECURSIVE ancestors(id) AS (
                SELECT parent_id FROM tag_hierarchy WHERE child_id = ?
                UNION
                SELECT th.parent_id FROM tag_hierarchy th
                JOIN ancestors a ON th.child_id = a.id
            )
            SELECT t.id, t.name, t.description
            FROM ancestors a
            JOIN tags t ON a.id = t.id
            ORDER BY t.name
            """,
            (tag_id,),
        )
        return [dict(row) for row in cursor.fetchall()]

    def get_descendants(self, tag_id: int) -> list[dict[str, Any]]:
        """
        Get all descendant tags of a tag (recursive children).

        Args:
            tag_id: Tag ID

        Returns:
            List[Dict[str, Any]]: List of descendant tag data
        """
        # Use recursive CTE to get all descendants
        cursor = self.conn.execute(
            """
            WITH RECURSIVE descendants(id) AS (
                SELECT child_id FROM tag_hierarchy WHERE parent_id = ?
                UNION
                SELECT th.child_id FROM tag_hierarchy th
                JOIN descendants d ON th.parent_id = d.id
            )
            SELECT t.id, t.name, t.description
            FROM descendants d
            JOIN tags t ON d.id = t.id
            ORDER BY t.name
            """,
            (tag_id,),
        )
        return [dict(row) for row in cursor.fetchall()]

    def get_siblings(self, tag_id: int) -> list[dict[str, Any]]:
        """
        Get sibling tags (tags that share a parent with the given tag).

        Args:
            tag_id: Tag ID

        Returns:
            List[Dict[str, Any]]: List of sibling tag data
        """
        cursor = self.conn.execute(
            """
            SELECT DISTINCT t.id, t.name, t.description
            FROM tag_hierarchy th1
            JOIN tag_hierarchy th2 ON th1.parent_id = th2.parent_id AND th1.child_id != th2.child_id
            JOIN tags t ON th2.child_id = t.id
            WHERE th1.child_id = ?
            ORDER BY t.name
            """,
            (tag_id,),
        )
        return [dict(row) for row in cursor.fetchall()]

    def is_ancestor(self, ancestor_id: int, descendant_id: int) -> bool:
        """
        Check if a tag is an ancestor of another tag.

        Args:
            ancestor_id: Potential ancestor tag ID
            descendant_id: Potential descendant tag ID

        Returns:
            bool: True if ancestor_id is an ancestor of descendant_id
        """
        cursor = self.conn.execute(
            """
            WITH RECURSIVE ancestors(id) AS (
                SELECT parent_id FROM tag_hierarchy WHERE child_id = ?
                UNION
                SELECT th.parent_id FROM tag_hierarchy th
                JOIN ancestors a ON th.child_id = a.id
            )
            SELECT COUNT(*) FROM ancestors WHERE id = ?
            """,
            (descendant_id, ancestor_id),
        )
        result = cursor.fetchone()
        count = int(result[0]) if result else 0
        return bool(count > 0)

    def is_related(self, tag1_id: int, tag2_id: int) -> bool:
        """
        Check if two tags are related in the hierarchy.

        Two tags are related if one is an ancestor of the other,
        or if they share a common ancestor.

        Args:
            tag1_id: First tag ID
            tag2_id: Second tag ID

        Returns:
            bool: True if the tags are related
        """
        if tag1_id == tag2_id:
            return True

        # Check if one is an ancestor of the other
        if self.is_ancestor(tag1_id, tag2_id) or self.is_ancestor(tag2_id, tag1_id):
            return True

        # Check if they share any common ancestors
        ancestors1 = {row["id"] for row in self.get_ancestors(tag1_id)}
        ancestors2 = {row["id"] for row in self.get_ancestors(tag2_id)}

        common_ancestors = ancestors1.intersection(ancestors2)
        return bool(len(common_ancestors) > 0)

    def get_path(self, tag_id: int) -> list[dict[str, Any]]:
        """
        Get the path from the root to the tag.

        If there are multiple paths, returns the shortest one.

        Args:
            tag_id: Tag ID

        Returns:
            List[Dict[str, Any]]: List of tag data in path order (root to tag)
        """
        # Get all ancestors
        ancestors = self.get_ancestors(tag_id)
        if not ancestors:
            # This tag has no ancestors, so it's a root
            cursor = self.conn.execute(
                "SELECT id, name, description FROM tags WHERE id = ?", (tag_id,)
            )
            tag = cursor.fetchone()
            if tag:
                return [dict(tag)]
            return []

        # Find roots (tags with no parents in the ancestors list)
        ancestor_ids = {a["id"] for a in ancestors}
        roots = []
        for ancestor in ancestors:
            has_parent = False
            for parent in self.get_parents(ancestor["id"]):
                if parent["id"] in ancestor_ids:
                    has_parent = True
                    break
            if not has_parent:
                roots.append(ancestor)

        # For each root, find the path to the tag
        paths = []
        for root in roots:
            path = self._find_path(root["id"], tag_id)
            if path:
                paths.append(path)

        if not paths:
            return []

        # Return the shortest path
        shortest_path = min(paths, key=len)

        # Convert tag IDs to tag data
        result = []
        for tag_id in shortest_path:
            cursor = self.conn.execute(
                "SELECT id, name, description FROM tags WHERE id = ?", (tag_id,)
            )
            tag = cursor.fetchone()
            if tag:
                result.append(dict(tag))

        return result

    def export_taxonomy(self, root_tag_id: int | None = None) -> dict[str, Any]:
        """
        Export the tag hierarchy as a nested dictionary.

        Args:
            root_tag_id: Optional root tag ID. If None, export the entire hierarchy.

        Returns:
            Dict[str, Any]: Nested dictionary representing the hierarchy
        """
        if root_tag_id is not None:
            # Export from a specific root
            return self._build_taxonomy_tree(root_tag_id)

        # Find all root tags (tags with no parents)
        cursor = self.conn.execute(
            """
            SELECT t.id, t.name, t.description
            FROM tags t
            WHERE t.id NOT IN (SELECT DISTINCT child_id FROM tag_hierarchy)
            ORDER BY t.name
            """
        )
        roots = [dict(row) for row in cursor.fetchall()]

        # Build a forest of taxonomies
        result = {}
        for root in roots:
            result[root["name"]] = self._build_taxonomy_tree(root["id"])

        return result

    def import_taxonomy(
        self, taxonomy: dict[str, Any], parent_id: int | None = None
    ) -> dict[str, int]:
        """
        Import a tag hierarchy from a nested dictionary.

        Args:
            taxonomy: Nested dictionary representing the hierarchy
            parent_id: Optional parent tag ID for the top level

        Returns:
            Dict[str, int]: Mapping of tag names to their IDs
        """
        tag_map = {}  # Map of tag names to IDs

        # First, create or get all the tags
        tags_to_process = []

        def collect_tags(tax, prefix=""):
            for name, value in tax.items():
                full_name = f"{prefix}.{name}" if prefix else name
                tags_to_process.append((full_name, None))  # (name, description)
                if isinstance(value, dict) and "children" in value:
                    collect_tags(value["children"], full_name)

        # Start with root level
        for name, value in taxonomy.items():
            desc = value.get("description") if isinstance(value, dict) else None
            tags_to_process.append((name, desc))
            if isinstance(value, dict) and "children" in value:
                collect_tags(value["children"], name)

        # Create all tags first
        for name, desc in tags_to_process:
            cursor = self.conn.execute("SELECT id FROM tags WHERE name = ?", (name,))
            row = cursor.fetchone()
            if row:
                tag_map[name] = row[0]
            else:
                cursor = self.conn.execute(
                    "INSERT INTO tags (name, description) VALUES (?, ?)", (name, desc)
                )
                self.conn.commit()
                tag_map[name] = cursor.lastrowid

        # Now create relationships
        def process_relationships(tax, parent_name=None):
            for name, value in tax.items():
                if parent_name and parent_name in tag_map and name in tag_map:
                    self.add_relationship(tag_map[parent_name], tag_map[name])

                if isinstance(value, dict) and "children" in value:
                    process_relationships(value["children"], name)

        # Process relationships
        process_relationships(taxonomy)

        # If a parent_id was provided, link all root nodes to it
        if parent_id is not None:
            for name in taxonomy.keys():
                if name in tag_map:
                    self.add_relationship(parent_id, tag_map[name])

        return tag_map

    def _would_create_cycle(self, parent_id: int, child_id: int) -> bool:
        """
        Check if adding a relationship would create a cycle.

        Args:
            parent_id: Parent tag ID
            child_id: Child tag ID

        Returns:
            bool: True if adding the relationship would create a cycle
        """
        if parent_id == child_id:
            return True

        # Check if child is already an ancestor of parent
        return self.is_ancestor(child_id, parent_id)

    def _find_path(self, start_id: int, end_id: int) -> list[int]:
        """
        Find a path from start_id to end_id in the hierarchy.

        Args:
            start_id: Starting tag ID
            end_id: Ending tag ID

        Returns:
            List[int]: List of tag IDs in path order, or empty list if no path
        """
        if start_id == end_id:
            return [start_id]

        # BFS to find shortest path
        queue = [(start_id, [start_id])]
        visited = {start_id}

        while queue:
            node, path = queue.pop(0)

            # Get children of current node
            children = self.get_children(node)
            for child in children:
                child_id = child["id"]
                if child_id == end_id:
                    return path + [child_id]

                if child_id not in visited:
                    visited.add(child_id)
                    queue.append((child_id, path + [child_id]))

        return []

    def _build_taxonomy_tree(self, tag_id: int) -> dict[str, Any]:
        """
        Build a nested dictionary representing the taxonomy tree.

        Args:
            tag_id: Root tag ID

        Returns:
            Dict[str, Any]: Nested dictionary representing the taxonomy
        """
        # Get the tag info
        cursor = self.conn.execute(
            "SELECT id, name, description FROM tags WHERE id = ?", (tag_id,)
        )
        tag = cursor.fetchone()
        if not tag:
            return {}

        result = {"id": tag["id"], "description": tag["description"]}

        # Get children
        children = self.get_children(tag_id)
        if children:
            result["children"] = {}
            for child in children:
                child_tree = self._build_taxonomy_tree(child["id"])
                if child_tree:
                    result["children"][child["name"]] = child_tree

        return result



================================================
File: src/the_aichemist_codex/backend/tagging/manager.py
================================================
"""
Tag management system for file organization.

This module provides the TagManager class, which is responsible for
managing file tags, including creating, retrieving, updating, and
deleting tags and their associations with files.
"""

import logging
import sqlite3
from pathlib import Path
from typing import Any

from .schema import TagSchema

logger = logging.getLogger(__name__)


class TagManager:
    """
    Manages file tagging operations.

    This class provides methods for creating, retrieving, updating, and
    deleting tags and their associations with files. It also provides
    methods for querying files by tags and retrieving tag statistics.
    """

    def __init__(self, db_path: Path):
        """
        Initialize the TagManager with a database path.

        Args:
            db_path: Path to the SQLite database file
        """
        self.db_path = db_path
        self.schema = TagSchema(db_path)

    async def initialize(self) -> None:
        """
        Initialize the tag manager and create database tables if needed.

        Raises:
            Exception: If initialization fails
        """
        await self.schema.initialize()
        logger.info("Initialized TagManager")

    async def close(self) -> None:
        """Close any resources used by the tag manager."""
        logger.debug("Closed TagManager")

    async def __aenter__(self) -> "TagManager":
        """Support for async context manager."""
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        """Support for async context manager."""
        await self.close()

    # Tag operations

    async def create_tag(self, name: str, description: str = "") -> int:
        """
        Create a new tag.

        Args:
            name: Tag name
            description: Tag description

        Returns:
            int: Tag ID

        Raises:
            Exception: If tag creation fails
        """
        # Normalize tag name (lowercase, strip whitespace)
        name = name.strip().lower()

        # Insert tag and return ID
        try:
            # Check if tag already exists
            existing_tag = await self.get_tag_by_name(name)
            if existing_tag:
                return existing_tag["id"]

            # Create new tag
            query = "INSERT INTO tags (name, description) VALUES (?, ?)"
            await self.schema.db.execute(query, (name, description), commit=True)

            # Get the inserted tag ID
            result = await self.schema.db.fetchone(
                "SELECT id FROM tags WHERE name = ?", (name,)
            )
            if result:
                tag_id = result[0]
                logger.debug(f"Created tag: {name} (id: {tag_id})")
                return tag_id

            raise ValueError(f"Failed to retrieve ID for newly created tag: {name}")

        except Exception as e:
            logger.error(f"Error creating tag '{name}': {e}")
            raise

    async def get_tag(self, tag_id: int) -> dict[str, Any] | None:
        """
        Get a tag by ID.

        Args:
            tag_id: Tag ID

        Returns:
            Dict containing tag data, or None if not found
        """
        try:
            result = await self.schema.db.fetchone(
                "SELECT * FROM tags WHERE id = ?", (tag_id,)
            )
            if result:
                return {
                    "id": result[0],
                    "name": result[1],
                    "description": result[2],
                    "created_at": result[3],
                    "modified_at": result[4],
                }
            return None
        except Exception as e:
            logger.error(f"Error getting tag with id {tag_id}: {e}")
            return None

    async def get_tag_by_name(self, name: str) -> dict[str, Any] | None:
        """
        Get a tag by name (case insensitive).

        Args:
            name: Tag name

        Returns:
            Dict containing tag data, or None if not found
        """
        try:
            # Normalize tag name (lowercase, strip whitespace)
            name = name.strip().lower()

            result = await self.schema.db.fetchone(
                "SELECT * FROM tags WHERE LOWER(name) = ?", (name,)
            )
            if result:
                return {
                    "id": result[0],
                    "name": result[1],
                    "description": result[2],
                    "created_at": result[3],
                    "modified_at": result[4],
                }
            return None
        except Exception as e:
            logger.error(f"Error getting tag with name '{name}': {e}")
            return None

    async def update_tag(
        self, tag_id: int, name: str | None = None, description: str | None = None
    ) -> bool:
        """
        Update a tag.

        Args:
            tag_id: Tag ID
            name: New tag name (optional)
            description: New tag description (optional)

        Returns:
            bool: True if updated, False if not found or not updated
        """
        try:
            # Get current tag data
            tag = await self.get_tag(tag_id)
            if not tag:
                return False

            # Prepare update data
            update_data = []
            params = []
            if name is not None:
                # Normalize tag name (lowercase, strip whitespace)
                name = name.strip().lower()
                update_data.append("name = ?")
                params.append(name)
            if description is not None:
                update_data.append("description = ?")
                params.append(description)

            if not update_data:
                # Nothing to update
                return False

            # Build and execute update query
            query = f"UPDATE tags SET {', '.join(update_data)} WHERE id = ?"
            params.append(tag_id)
            await self.schema.db.execute(query, tuple(params), commit=True)
            logger.debug(f"Updated tag {tag_id}")
            return True

        except Exception as e:
            logger.error(f"Error updating tag {tag_id}: {e}")
            return False

    async def delete_tag(self, tag_id: int) -> bool:
        """
        Delete a tag.

        Args:
            tag_id: Tag ID

        Returns:
            bool: True if deleted, False if not found or not deleted
        """
        try:
            # Check if tag exists
            tag = await self.get_tag(tag_id)
            if not tag:
                return False

            # Delete tag (cascade will delete from tag_hierarchy and file_tags)
            await self.schema.db.execute(
                "DELETE FROM tags WHERE id = ?", (tag_id,), commit=True
            )
            logger.debug(f"Deleted tag {tag_id}")
            return True

        except Exception as e:
            logger.error(f"Error deleting tag {tag_id}: {e}")
            return False

    async def get_all_tags(self) -> list[dict[str, Any]]:
        """
        Get all tags.

        Returns:
            List of dicts containing tag data
        """
        try:
            results = await self.schema.db.fetchall("SELECT * FROM tags ORDER BY name")
            return [
                {
                    "id": row[0],
                    "name": row[1],
                    "description": row[2],
                    "created_at": row[3],
                    "modified_at": row[4],
                }
                for row in results
            ]
        except Exception as e:
            logger.error(f"Error getting all tags: {e}")
            return []

    # File tag operations

    async def add_file_tag(
        self,
        file_path: Path,
        tag_id: int | None = None,
        tag_name: str | None = None,
        source: str = "manual",
        confidence: float = 1.0,
    ) -> bool:
        """
        Add a tag to a file.

        Either tag_id or tag_name must be provided.

        Args:
            file_path: Path to the file
            tag_id: ID of the tag to add
            tag_name: Name of the tag to add (alternative to tag_id)
            source: Source of the tag (e.g., "manual", "auto")
            confidence: Confidence score (0.0 to 1.0)

        Returns:
            bool: True if a new tag was added, False if an existing tag was updated

        Raises:
            ValueError: If neither tag_id nor tag_name is provided
            Exception: If tag addition fails
        """
        if tag_id is None and tag_name is None:
            raise ValueError("Either tag_id or tag_name must be provided")

        file_path_str = str(file_path.resolve())

        # If tag_name is provided, get or create the tag
        if tag_id is None and tag_name is not None:
            tag = await self.get_tag_by_name(tag_name)
            if tag:
                tag_id = tag["id"]
            else:
                tag_id = await self.create_tag(tag_name)

        # At this point, tag_id should be set
        assert tag_id is not None, "tag_id should not be None at this point"

        # Try to insert the file tag
        try:
            # First try to insert
            await self.schema.db.execute(
                "INSERT INTO file_tags (file_path, tag_id, source, confidence) VALUES (?, ?, ?, ?)",
                (file_path_str, tag_id, source, confidence),
                commit=True,
            )
            logger.debug(f"Added tag {tag_id} to file '{file_path}'")
            return True
        except sqlite3.IntegrityError:
            # Update if already exists
            await self.schema.db.execute(
                "UPDATE file_tags SET source = ?, confidence = ? WHERE file_path = ? AND tag_id = ?",
                (source, confidence, file_path_str, tag_id),
                commit=True,
            )
            logger.debug(f"Updated tag {tag_id} for file '{file_path}'")
            return False
        except Exception as e:
            logger.error(f"Error adding tag {tag_id} to file '{file_path}': {e}")
            raise

    async def add_file_tags(
        self, file_path: Path, tags: list[tuple[str, float]], source: str = "auto"
    ) -> int:
        """
        Add multiple tags to a file.

        Args:
            file_path: Path to the file
            tags: List of (tag_name, confidence) tuples
            source: Source of the tags

        Returns:
            int: Number of tags added
        """
        count = 0
        for tag_name, confidence in tags:
            try:
                added = await self.add_file_tag(
                    file_path=file_path,
                    tag_name=tag_name,
                    source=source,
                    confidence=confidence,
                )
                if added:
                    count += 1
            except Exception as e:
                logger.error(f"Error adding tag '{tag_name}' to '{file_path}': {e}")
        return count

    async def remove_file_tag(self, file_path: Path, tag_id: int) -> bool:
        """
        Remove a tag from a file.

        Args:
            file_path: Path to the file
            tag_id: Tag ID

        Returns:
            bool: True if the tag was removed, False if not found
        """
        file_path_str = str(file_path.resolve())
        try:
            result = await self.schema.db.fetchone(
                "SELECT 1 FROM file_tags WHERE file_path = ? AND tag_id = ?",
                (file_path_str, tag_id),
            )
            if not result:
                return False

            await self.schema.db.execute(
                "DELETE FROM file_tags WHERE file_path = ? AND tag_id = ?",
                (file_path_str, tag_id),
                commit=True,
            )
            logger.debug(f"Removed tag {tag_id} from file '{file_path}'")
            return True
        except Exception as e:
            logger.error(f"Error removing tag {tag_id} from file '{file_path}': {e}")
            return False

    async def get_file_tags(self, file_path: Path) -> list[dict[str, Any]]:
        """
        Get all tags for a file.

        Args:
            file_path: Path to the file

        Returns:
            List of dicts containing tag data
        """
        file_path_str = str(file_path.resolve())
        try:
            results = await self.schema.db.fetchall(
                """
                SELECT t.id, t.name, t.description, ft.source, ft.confidence
                FROM file_tags ft
                JOIN tags t ON ft.tag_id = t.id
                WHERE ft.file_path = ?
                ORDER BY t.name
                """,
                (file_path_str,),
            )
            return [
                {
                    "id": row[0],
                    "name": row[1],
                    "description": row[2],
                    "source": row[3],
                    "confidence": row[4],
                }
                for row in results
            ]
        except Exception as e:
            logger.error(f"Error getting tags for file '{file_path}': {e}")
            return []

    # Query operations

    async def get_files_by_tag(
        self, tag_id: int | None = None, tag_name: str | None = None
    ) -> list[str]:
        """
        Get all files with a specific tag.

        Either tag_id or tag_name must be provided.

        Args:
            tag_id: Tag ID
            tag_name: Tag name

        Returns:
            List[str]: List of file paths

        Raises:
            ValueError: If neither tag_id nor tag_name is provided
        """
        if tag_id is None and tag_name is None:
            raise ValueError("Either tag_id or tag_name must be provided")

        # If tag_name is provided, get tag ID
        if tag_id is None and tag_name is not None:
            tag = await self.get_tag_by_name(tag_name)
            if not tag:
                return []
            tag_id = tag["id"]

        # At this point, tag_id should be set
        assert tag_id is not None, "tag_id should not be None at this point"

        try:
            results = await self.schema.db.fetchall(
                "SELECT file_path FROM file_tags WHERE tag_id = ?", (tag_id,)
            )
            return [row[0] for row in results]
        except Exception as e:
            logger.error(f"Error getting files for tag {tag_id}: {e}")
            return []

    async def get_files_by_tags(
        self, tag_ids: list[int], require_all: bool = False
    ) -> list[str]:
        """
        Get files that have the specified tags.

        Args:
            tag_ids: List of tag IDs
            require_all: If True, files must have ALL tags; if False, ANY tag

        Returns:
            List[str]: List of file paths
        """
        if not tag_ids:
            return []

        try:
            if require_all:
                # Files must have ALL the specified tags
                placeholders = ",".join("?" for _ in tag_ids)
                results = await self.schema.db.fetchall(
                    f"""
                    SELECT file_path FROM file_tags
                    WHERE tag_id IN ({placeholders})
                    GROUP BY file_path
                    HAVING COUNT(DISTINCT tag_id) = ?
                    """,
                    tuple(tag_ids) + (len(tag_ids),),
                )
            else:
                # Files can have ANY of the specified tags
                placeholders = ",".join("?" for _ in tag_ids)
                results = await self.schema.db.fetchall(
                    f"""
                    SELECT DISTINCT file_path FROM file_tags
                    WHERE tag_id IN ({placeholders})
                    """,
                    tuple(tag_ids),
                )

            return [row[0] for row in results]
        except Exception as e:
            logger.error(f"Error getting files by tags: {e}")
            return []

    async def get_tag_counts(self) -> list[dict[str, Any]]:
        """
        Get all tags with their usage counts.

        Returns:
            List[Dict[str, Any]]: List of tags with count information
        """
        try:
            results = await self.schema.db.fetchall(
                """
                SELECT t.id, t.name, t.description, COUNT(ft.file_path) as count
                FROM tags t
                LEFT JOIN file_tags ft ON t.id = ft.tag_id
                GROUP BY t.id
                ORDER BY count DESC, t.name
                """
            )

            return [
                {
                    "id": row[0],
                    "name": row[1],
                    "description": row[2],
                    "count": row[3],
                }
                for row in results
            ]
        except Exception as e:
            logger.error(f"Error getting tag counts: {e}")
            return []

    # Batch operations

    async def batch_add_tags(self, tag_data: list[dict[str, Any]]) -> int:
        """
        Add multiple tags in a batch operation.

        Args:
            tag_data: List of dicts with 'name' and optional 'description' keys

        Returns:
            int: Number of tags added
        """
        if not tag_data:
            return 0

        try:
            # Prepare data for batch insert
            tag_entries = [
                (d["name"].strip().lower(), d.get("description", "")) for d in tag_data
            ]

            # Execute batch insert
            await self.schema.db.executemany(
                "INSERT OR IGNORE INTO tags (name, description) VALUES (?, ?)",
                tag_entries,
            )

            # Since we can't directly get the count from executemany,
            # we'll count by checking which tags now exist
            added_count = 0
            for tag_info in tag_data:
                tag_name = tag_info["name"].strip().lower()
                tag = await self.get_tag_by_name(tag_name)
                if tag:
                    added_count += 1

            logger.debug(f"Added {added_count} tags in batch")
            return added_count
        except Exception as e:
            logger.error(f"Error in batch_add_tags: {e}")
            return 0

    async def batch_add_file_tags(self, file_tags: list[dict[str, Any]]) -> int:
        """
        Add multiple file-tag associations in a batch operation.

        Args:
            file_tags: List of dicts with keys:
                       - file_path: Path to the file
                       - tag_name: Tag name
                       - source: Source of the tag (optional)
                       - confidence: Confidence score (optional)

        Returns:
            int: Number of file tags added
        """
        if not file_tags:
            return 0

        # First, ensure all tags exist and get their IDs
        tag_names = set(item["tag_name"].strip().lower() for item in file_tags)
        tag_id_map = {}

        for tag_name in tag_names:
            tag = await self.get_tag_by_name(tag_name)
            if tag:
                tag_id_map[tag_name] = tag["id"]
            else:
                # Create tag if it doesn't exist
                tag_id = await self.create_tag(tag_name)
                tag_id_map[tag_name] = tag_id

        # Prepare data for batch insert
        data = []
        for item in file_tags:
            tag_name = item["tag_name"].strip().lower()
            if tag_name in tag_id_map:
                file_path_str = str(Path(item["file_path"]).resolve())
                data.append(
                    (
                        file_path_str,
                        tag_id_map[tag_name],
                        item.get("source", "auto"),
                        item.get("confidence", 1.0),
                    )
                )

        count = 0
        if data:
            try:
                # Execute batch insert using the INSERT OR REPLACE pattern
                query = """
                INSERT INTO file_tags (file_path, tag_id, source, confidence)
                VALUES (?, ?, ?, ?)
                ON CONFLICT(file_path, tag_id) DO UPDATE SET
                source = excluded.source,
                confidence = excluded.confidence
                """

                await self.schema.db.executemany(query, data)
                count = len(data)
            except Exception as e:
                logger.error(f"Error in batch_add_file_tags: {e}")

        logger.debug(f"Added {count} file tags in batch")
        return count

    # Cleanup and maintenance

    async def remove_orphaned_tags(self) -> int:
        """
        Remove tags that are not associated with any files.

        Returns:
            int: Number of tags removed
        """
        try:
            # First, identify orphaned tags
            results = await self.schema.db.fetchall(
                """
                SELECT id FROM tags
                WHERE id NOT IN (SELECT DISTINCT tag_id FROM file_tags)
                """
            )

            orphaned_tag_ids = [row[0] for row in results]

            if not orphaned_tag_ids:
                return 0

            # Delete the orphaned tags
            for tag_id in orphaned_tag_ids:
                await self.delete_tag(tag_id)

            count = len(orphaned_tag_ids)
            logger.debug(f"Removed {count} orphaned tags")
            return count
        except Exception as e:
            logger.error(f"Error removing orphaned tags: {e}")
            return 0

    async def clean_missing_files(self) -> int:
        """
        Remove tags for files that no longer exist.

        Returns:
            int: Number of file tags removed
        """
        try:
            # Get all file paths
            results = await self.schema.db.fetchall(
                "SELECT DISTINCT file_path FROM file_tags"
            )

            all_paths = [row[0] for row in results]
            missing_paths = []

            # Check which files no longer exist
            for path_str in all_paths:
                if not Path(path_str).exists():
                    missing_paths.append(path_str)

            if not missing_paths:
                return 0

            # Delete tags for missing files
            count = 0
            for path_str in missing_paths:
                # Execute delete for each missing file
                await self.schema.db.execute(
                    "DELETE FROM file_tags WHERE file_path = ?",
                    (path_str,),
                    commit=True,
                )
                count += 1

            logger.debug(f"Removed tags for {count} missing files")
            return count
        except Exception as e:
            logger.error(f"Error cleaning missing files: {e}")
            return 0

    async def get_tag_suggestions(self, file_path: Path) -> list[dict[str, Any]]:
        """
        Get tag suggestions for a file based on similar files.

        This method implements a collaborative filtering approach by finding files
        with similar extensions or in the same directory and recommending their tags.

        Args:
            file_path: Path to the file

        Returns:
            List[Dict[str, Any]]: List of suggested tags with scores
        """
        file_path_str = str(file_path.resolve())
        suggestions = {}

        try:
            # Get file directory and extension
            path = Path(file_path_str)
            directory = str(path.parent)
            extension = path.suffix.lower()

            # Find tags used on files with the same extension
            if extension:
                ext_results = await self.schema.db.fetchall(
                    """
                    SELECT t.id, t.name, COUNT(*) as count
                    FROM file_tags ft
                    JOIN tags t ON ft.tag_id = t.id
                    WHERE ft.file_path LIKE ?
                    AND ft.file_path != ?
                    GROUP BY t.id
                    ORDER BY count DESC
                    LIMIT 20
                    """,
                    (f"%{extension}", file_path_str),
                )

                # Add to suggestions with weight based on frequency
                max_count = max([row[2] for row in ext_results]) if ext_results else 1
                for row in ext_results:
                    tag_id, tag_name, count = row
                    score = min(0.85, 0.5 + (count / max_count) * 0.35)
                    suggestions[tag_name] = {
                        "name": tag_name,
                        "score": score,
                        "reason": "extension",
                    }

            # Find tags used on files in the same directory
            dir_results = await self.schema.db.fetchall(
                """
                SELECT t.id, t.name, COUNT(*) as count
                FROM file_tags ft
                JOIN tags t ON ft.tag_id = t.id
                WHERE ft.file_path LIKE ?
                AND ft.file_path != ?
                GROUP BY t.id
                ORDER BY count DESC
                LIMIT 20
                """,
                (f"{directory}%", file_path_str),
            )

            # Add to suggestions with weight based on frequency
            max_count = max([row[2] for row in dir_results]) if dir_results else 1
            for row in dir_results:
                tag_id, tag_name, count = row
                score = min(0.8, 0.5 + (count / max_count) * 0.3)
                if tag_name in suggestions:
                    # Take the higher score if already suggested
                    if score > suggestions[tag_name]["score"]:
                        suggestions[tag_name]["score"] = score
                        suggestions[tag_name]["reason"] = "directory"
                else:
                    suggestions[tag_name] = {
                        "name": tag_name,
                        "score": score,
                        "reason": "directory",
                    }

            # Convert to list and sort by score
            result = list(suggestions.values())
            result.sort(key=lambda x: x["score"], reverse=True)

            return result

        except Exception as e:
            logger.error(f"Error getting tag suggestions for file '{file_path}': {e}")
            return []



================================================
File: src/the_aichemist_codex/backend/tagging/schema.py
================================================
"""
Database schema for tag management system.

This module defines the SQLite schema for storing tags, tag hierarchies,
and file-tag associations.
"""

import logging
from pathlib import Path

from the_aichemist_codex.backend.utils.sqlasync_io import AsyncSQL

logger = logging.getLogger(__name__)

# SQL statements for creating database tables
CREATE_TAGS_TABLE = """
CREATE TABLE IF NOT EXISTS tags (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    modified_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
"""

CREATE_TAG_HIERARCHY_TABLE = """
CREATE TABLE IF NOT EXISTS tag_hierarchy (
    parent_id INTEGER NOT NULL,
    child_id INTEGER NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (parent_id, child_id),
    FOREIGN KEY (parent_id) REFERENCES tags (id) ON DELETE CASCADE,
    FOREIGN KEY (child_id) REFERENCES tags (id) ON DELETE CASCADE,
    CHECK (parent_id != child_id)
);
"""

CREATE_FILE_TAGS_TABLE = """
CREATE TABLE IF NOT EXISTS file_tags (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    file_path TEXT NOT NULL,
    tag_id INTEGER NOT NULL,
    source TEXT NOT NULL, -- 'manual', 'auto', 'suggested'
    confidence REAL DEFAULT 1.0,
    added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (tag_id) REFERENCES tags (id) ON DELETE CASCADE,
    UNIQUE (file_path, tag_id)
);
"""

CREATE_TAG_INDEX = """
CREATE INDEX IF NOT EXISTS idx_tags_name ON tags (name);
"""

CREATE_FILE_TAGS_PATH_INDEX = """
CREATE INDEX IF NOT EXISTS idx_file_tags_path ON file_tags (file_path);
"""

CREATE_FILE_TAGS_TAG_INDEX = """
CREATE INDEX IF NOT EXISTS idx_file_tags_tag_id ON file_tags (tag_id);
"""

# Triggers to update modified_at timestamp
CREATE_TAGS_UPDATE_TRIGGER = """
CREATE TRIGGER IF NOT EXISTS update_tags_modified_at
AFTER UPDATE ON tags
BEGIN
    UPDATE tags SET modified_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
END;
"""


class TagSchema:
    """
    Helper class for managing the tag database schema.

    This class provides methods for common database operations related
    to the tag management system.
    """

    def __init__(self, db_path: Path):
        """
        Initialize the TagSchema with a database path.

        Args:
            db_path: Path to the SQLite database file
        """
        self.db_path = db_path
        self.db = AsyncSQL(db_path)
        self._initialized = False

    async def initialize(self) -> None:
        """
        Initialize the database schema.

        Raises:
            Exception: If database initialization fails
        """
        try:
            # Ensure parent directory exists
            self.db_path.parent.mkdir(parents=True, exist_ok=True)

            # Create tables
            await self.db.execute(CREATE_TAGS_TABLE, commit=True)
            await self.db.execute(CREATE_TAG_HIERARCHY_TABLE, commit=True)
            await self.db.execute(CREATE_FILE_TAGS_TABLE, commit=True)

            # Create indexes
            await self.db.execute(CREATE_TAG_INDEX, commit=True)
            await self.db.execute(CREATE_FILE_TAGS_PATH_INDEX, commit=True)
            await self.db.execute(CREATE_FILE_TAGS_TAG_INDEX, commit=True)

            # Create triggers
            await self.db.execute(CREATE_TAGS_UPDATE_TRIGGER, commit=True)

            self._initialized = True
            logger.info(f"Initialized tag database at {self.db_path}")

        except Exception as e:
            logger.error(f"Failed to initialize tag database: {e}")
            raise

    async def reset(self) -> None:
        """
        Reset the database by dropping and recreating all tables.

        This is primarily intended for testing.

        Raises:
            Exception: If reset fails
        """
        if not self._initialized:
            await self.initialize()

        try:
            # Drop tables in reverse order of dependencies
            await self.db.execute("DROP TABLE IF EXISTS file_tags", commit=True)
            await self.db.execute("DROP TABLE IF EXISTS tag_hierarchy", commit=True)
            await self.db.execute("DROP TABLE IF EXISTS tags", commit=True)

            # Recreate tables
            await self.db.execute(CREATE_TAGS_TABLE, commit=True)
            await self.db.execute(CREATE_TAG_HIERARCHY_TABLE, commit=True)
            await self.db.execute(CREATE_FILE_TAGS_TABLE, commit=True)

            # Recreate indexes
            await self.db.execute(CREATE_TAG_INDEX, commit=True)
            await self.db.execute(CREATE_FILE_TAGS_PATH_INDEX, commit=True)
            await self.db.execute(CREATE_FILE_TAGS_TAG_INDEX, commit=True)

            # Recreate triggers
            await self.db.execute(CREATE_TAGS_UPDATE_TRIGGER, commit=True)

            logger.info("Reset tag database schema")

        except Exception as e:
            logger.error(f"Failed to reset tag database: {e}")
            raise



================================================
File: src/the_aichemist_codex/backend/tagging/suggester.py
================================================
"""
Tag suggestion system for automated tagging based on file content.

This module provides functionality to suggest tags for files based on
their content, metadata, and similarity to previously tagged files.
"""

import logging
from pathlib import Path

from the_aichemist_codex.backend.file_reader.file_metadata import FileMetadata

from .classifier import TagClassifier
from .manager import TagManager

logger = logging.getLogger(__name__)


class TagSuggester:
    """
    Suggests tags for files based on multiple strategies.

    This class combines multiple tag suggestion strategies, including
    machine learning classification, collaborative filtering, and
    content analysis, to provide comprehensive tag recommendations.
    """

    def __init__(
        self,
        tag_manager: TagManager,
        classifier: TagClassifier | None = None,
        model_dir: Path | None = None,
    ):
        """
        Initialize the tag suggester.

        Args:
            tag_manager: TagManager instance for accessing tag data
            classifier: Optional TagClassifier instance
            model_dir: Optional directory for model storage
        """
        self.tag_manager = tag_manager
        # Use a default model directory if none is provided
        default_model_dir = Path.home() / ".aichemist" / "models"
        self.classifier = classifier or TagClassifier(model_dir or default_model_dir)

    async def suggest_tags(
        self,
        file_metadata: FileMetadata,
        min_confidence: float = 0.6,
        max_suggestions: int = 10,
    ) -> list[tuple[str, float]]:
        """
        Suggest tags for a file using multiple strategies.

        Args:
            file_metadata: FileMetadata object
            min_confidence: Minimum confidence threshold for suggestions
            max_suggestions: Maximum number of suggestions to return

        Returns:
            List[Tuple[str, float]]: List of (tag_name, confidence) tuples
        """
        suggestions = []

        # Get suggestions from classifier
        classifier_suggestions = await self._get_classifier_suggestions(
            file_metadata, min_confidence
        )

        # Get collaborative filtering suggestions
        if file_metadata.path:
            cf_suggestions = await self._get_collaborative_suggestions(
                Path(file_metadata.path), min_confidence
            )
        else:
            cf_suggestions = []

        # Get content-based suggestions
        content_suggestions = await self._get_content_based_suggestions(
            file_metadata, min_confidence
        )

        # Combine and deduplicate suggestions
        all_suggestions = {}

        # Add with different weights based on source
        for tag, conf in classifier_suggestions:
            all_suggestions[tag] = conf * 1.0  # Full weight for ML classifier

        for tag, conf in cf_suggestions:
            if tag in all_suggestions:
                # Take max confidence if already suggested
                all_suggestions[tag] = max(all_suggestions[tag], conf * 0.8)
            else:
                all_suggestions[tag] = (
                    conf * 0.8
                )  # 80% weight for collaborative filtering

        for tag, conf in content_suggestions:
            if tag in all_suggestions:
                all_suggestions[tag] = max(all_suggestions[tag], conf * 0.9)
            else:
                all_suggestions[tag] = conf * 0.9  # 90% weight for content-based

        # Sort by confidence
        suggestions = [
            (tag, conf)
            for tag, conf in all_suggestions.items()
            if conf >= min_confidence
        ]
        suggestions.sort(key=lambda x: x[1], reverse=True)

        return suggestions[:max_suggestions]

    async def _get_classifier_suggestions(
        self, file_metadata: FileMetadata, min_confidence: float
    ) -> list[tuple[str, float]]:
        """
        Get tag suggestions from the classifier.

        Args:
            file_metadata: FileMetadata object
            min_confidence: Minimum confidence threshold

        Returns:
            List[Tuple[str, float]]: List of (tag_name, confidence) tuples
        """
        try:
            return await self.classifier.classify(
                file_metadata, confidence_threshold=min_confidence
            )
        except Exception as e:
            logger.error(f"Error getting classifier suggestions: {e}")
            return []

    async def _get_collaborative_suggestions(
        self, file_path: Path, min_confidence: float
    ) -> list[tuple[str, float]]:
        """
        Get tag suggestions based on similar files (collaborative filtering).

        Args:
            file_path: Path to the file
            min_confidence: Minimum confidence threshold

        Returns:
            List[Tuple[str, float]]: List of (tag_name, confidence) tuples
        """
        try:
            # Get suggestions from TagManager
            suggestions = await self.tag_manager.get_tag_suggestions(file_path)

            # Convert to required format
            return [
                (tag["name"], tag["score"])
                for tag in suggestions
                if tag["score"] >= min_confidence
            ]

        except Exception as e:
            logger.error(f"Error getting collaborative suggestions: {e}")
            return []

    async def _get_content_based_suggestions(
        self, file_metadata: FileMetadata, min_confidence: float
    ) -> list[tuple[str, float]]:
        """
        Get tag suggestions based on file content and metadata.

        This method analyzes the content and metadata of the file to
        suggest tags based on keywords, topics, entities, etc.

        Args:
            file_metadata: FileMetadata object
            min_confidence: Minimum confidence threshold

        Returns:
            List[Tuple[str, float]]: List of (tag_name, confidence) tuples
        """
        suggestions = []

        # Suggest tags based on file extension
        if file_metadata.path:
            path = Path(file_metadata.path)
            if path.suffix:
                extension = path.suffix.lstrip(".")
                suggestions.append((f"ext:{extension}", 0.9))

        # Suggest tags based on mime type
        if file_metadata.mime_type:
            mime_parts = file_metadata.mime_type.split("/")
            if len(mime_parts) == 2:
                main_type, sub_type = mime_parts
                suggestions.append((f"type:{main_type}", 0.9))
                if sub_type != "*":
                    suggestions.append((f"format:{sub_type}", 0.85))

        # Suggest tags based on extracted topics
        if hasattr(file_metadata, "topics") and file_metadata.topics:
            for topic_dict in file_metadata.topics:
                for topic, score in topic_dict.items():
                    if score >= min_confidence:
                        suggestions.append((f"topic:{topic}", float(score)))

        # Suggest tags based on keywords
        if hasattr(file_metadata, "keywords") and file_metadata.keywords:
            for keyword in file_metadata.keywords[:5]:  # Limit to top 5 keywords
                suggestions.append((keyword, 0.8))

        # Suggest tags based on language
        if hasattr(file_metadata, "language") and file_metadata.language:
            suggestions.append((f"lang:{file_metadata.language}", 0.95))

        # Suggest tags based on content type
        if hasattr(file_metadata, "content_type") and file_metadata.content_type:
            suggestions.append((f"content:{file_metadata.content_type}", 0.9))

        # Filter by confidence
        return [(tag, conf) for tag, conf in suggestions if conf >= min_confidence]

    async def analyze_directory(
        self,
        directory: Path,
        recursive: bool = True,
        min_confidence: float = 0.7,
        apply_tags: bool = False,
    ) -> dict[str, list[tuple[str, float]]]:
        """
        Analyze a directory and suggest tags for all files.

        Args:
            directory: Directory path
            recursive: Whether to recursively scan subdirectories
            min_confidence: Minimum confidence threshold
            apply_tags: Whether to apply suggested tags automatically

        Returns:
            Dict[str, List[Tuple[str, float]]]: Mapping of file paths to suggested tags
        """
        from the_aichemist_codex.backend.file_reader.file_reader import FileReader

        results = {}

        # Create a file reader
        file_reader = FileReader()

        # Scan the directory
        pattern = "**/*" if recursive else "*"
        files = list(directory.glob(pattern))

        # Process each file
        for file_path in files:
            if file_path.is_file():
                try:
                    # Process the file to get metadata
                    metadata = await file_reader.process_file(file_path)

                    # Get tag suggestions
                    suggestions = await self.suggest_tags(
                        metadata, min_confidence=min_confidence
                    )

                    if suggestions:
                        results[str(file_path)] = suggestions

                        # Apply tags if requested
                        if apply_tags and suggestions:
                            await self.tag_manager.add_file_tags(
                                file_path=file_path, tags=suggestions, source="auto"
                            )

                except Exception as e:
                    logger.error(f"Error processing file {file_path}: {e}")

        return results

    async def batch_suggest_tags(
        self,
        file_paths: list[Path],
        min_confidence: float = 0.7,
        apply_tags: bool = False,
    ) -> dict[str, list[tuple[str, float]]]:
        """
        Suggest tags for multiple files in batch.

        Args:
            file_paths: List of file paths
            min_confidence: Minimum confidence threshold
            apply_tags: Whether to apply suggested tags automatically

        Returns:
            Dict[str, List[Tuple[str, float]]]: Mapping of file paths to suggested tags
        """
        from the_aichemist_codex.backend.file_reader.file_reader import FileReader

        results = {}

        # Create a file reader
        file_reader = FileReader()

        # Process each file
        for file_path in file_paths:
            if file_path.is_file():
                try:
                    # Process the file to get metadata
                    metadata = await file_reader.process_file(file_path)

                    # Get tag suggestions
                    suggestions = await self.suggest_tags(
                        metadata, min_confidence=min_confidence
                    )

                    if suggestions:
                        results[str(file_path)] = suggestions

                        # Apply tags if requested
                        if apply_tags and suggestions:
                            await self.tag_manager.add_file_tags(
                                file_path=file_path, tags=suggestions, source="auto"
                            )

                except Exception as e:
                    logger.error(f"Error processing file {file_path}: {e}")

        return results

