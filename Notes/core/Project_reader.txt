
================================================
File: src/the_aichemist_codex/backend/project_reader/__init__.py
================================================
"""Project reader module for analyzing and summarizing code."""

from .code_summary import summarize_project
from .notebooks import NotebookConverter
from .tags import parse_tag
from .token_counter import TokenAnalyzer
from .version import InvalidVersion, Version

__all__ = [
    "InvalidVersion",
    "NotebookConverter",
    "TokenAnalyzer",
    "Version",
    "parse_tag",
    "summarize_project",
]



================================================
File: src/the_aichemist_codex/backend/project_reader/code_summary.py
================================================
"""Analyzes Python code and generates structured summaries."""

import argparse
import ast
import asyncio
import json
import logging
from pathlib import Path

from the_aichemist_codex.backend.output_formatter.json_writer import save_as_json_async
from the_aichemist_codex.backend.output_formatter.markdown_writer import (
    save_as_markdown,
)
from the_aichemist_codex.backend.utils.async_io import AsyncFileReader
from the_aichemist_codex.backend.utils.safety import SafeFileHandler

logger = logging.getLogger(__name__)


def get_function_metadata(node):
    """Extracts function metadata including decorators and return types."""
    decorators = [d.id for d in node.decorator_list if isinstance(d, ast.Name)]
    return_type = ast.unparse(node.returns) if node.returns else None

    return {
        "name": node.name,
        "args": [arg.arg for arg in node.args.args],
        "decorators": decorators,
        "return_type": return_type,
        "lineno": node.lineno,
    }


async def process_file(file_path: Path):
    """Extracts function and class details from a Python file, including docstrings and line numbers."""
    try:
        code = await AsyncFileReader.read_text(file_path)
        tree = ast.parse(code, filename=str(file_path))

        file_summary = ast.get_docstring(tree) or "No summary available."
        summaries = []

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                docstring = ast.get_docstring(node) or "No docstring provided."
                summaries.append(
                    {
                        "name": node.name,
                        "args": [arg.arg for arg in node.args.args],
                        "lineno": node.lineno,
                        "docstring": docstring,
                    }
                )

        folder_name = file_path.parent.name  # Extracts the folder name

        return file_path.resolve().as_posix(), {
            "summary": file_summary,
            "folder": folder_name,
            "functions": summaries,
        }

    except SyntaxError as e:
        logging.error(f"Syntax error in {file_path}: {e}")
        return file_path.resolve().as_posix(), {
            "summary": "Syntax error.",
            "folder": file_path.parent.name,
            "functions": [],
        }
    except Exception as e:
        logging.error(f"Error processing {file_path}: {e}")
        return file_path.resolve().as_posix(), {
            "summary": "Processing error.",
            "folder": file_path.parent.name,
            "functions": [],
        }


async def summarize_code(directory: Path):
    """Analyzes Python code in a directory, skipping ignored files."""
    directory = directory.resolve()  # Ensure absolute path

    # ✅ Instead of using `rglob`, manually scan to filter out directories first
    python_files = []
    for path in directory.glob("**/*.py"):
        if SafeFileHandler.should_ignore(path):
            continue  # Skip ignored files and directories
        python_files.append(path)

    if not python_files:
        logger.warning(
            f"No Python files found in {directory} after filtering ignored paths."
        )

    tasks = [process_file(file) for file in python_files]
    results = await asyncio.gather(*tasks, return_exceptions=True)  # Handle errors

    valid_results = {}
    for res in results:
        if isinstance(res, tuple) and len(res) == 2:  # Ensure correct format
            valid_results[res[0]] = res[1]
        else:
            logging.error(f"Invalid result from process_file(): {res}")

    return valid_results


async def summarize_project(directory: Path, output_markdown: Path, output_json: Path):
    """Runs the code summarization process and saves multiple output formats."""
    summary = await summarize_code(directory)

    # ✅ Debugging: Log output before saving
    logger.info(
        f"Summarization completed. Sample output: {json.dumps(list(summary.items())[:2], indent=4)}"
    )

    if not summary:
        logger.error("No files were analyzed. The summary is empty.")

    await save_as_markdown(output_markdown, summary, {}, "Project Code Summary")
    await save_as_json_async(summary, output_json)

    return summary


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Summarize Python code.")
    parser.add_argument("directory", type=Path, help="Directory to analyze.")
    args = parser.parse_args()

    input_directory = args.directory.resolve()  # Ensure absolute path
    logging.info(f"Starting code analysis for {input_directory}")

    output_json_file = input_directory / "code_summary.json"
    output_md_file = input_directory / "code_summary.md"

    summary = asyncio.run(
        summarize_project(input_directory, output_md_file, output_json_file)
    )

    logging.info(f"Code summary saved to {output_json_file}")
    logging.info(f"Markdown summary saved to {output_md_file}")



================================================
File: src/the_aichemist_codex/backend/project_reader/notebooks.py
================================================
"""Jupyter notebook processing for project_reader."""

import json
import logging
from pathlib import Path

from the_aichemist_codex.backend.utils import AsyncFileIO
from the_aichemist_codex.backend.utils.errors import NotebookProcessingError

logger = logging.getLogger(__name__)


class NotebookConverter:
    """Convert Jupyter notebooks to Python scripts and extract metadata."""

    @staticmethod
    async def to_script_async(notebook_path: Path) -> str:
        """Convert notebook to Python script asynchronously."""
        try:
            # Use AsyncFileIO to read the notebook file
            notebook_content = await AsyncFileIO.read_text(notebook_path)
            if notebook_content.startswith("# "):  # Error message or skipped file
                raise NotebookProcessingError(
                    f"Error reading notebook: {notebook_content}"
                )

            notebook_dict = json.loads(notebook_content)

            # Extract only code cells
            code_cells = []
            for cell in notebook_dict.get("cells", []):
                if cell.get("cell_type") == "code":
                    source = cell.get("source", "")
                    if isinstance(source, list):
                        code_cells.append("".join(source))
                    elif isinstance(source, str):
                        code_cells.append(source)

            return "\n\n".join(code_cells)
        except json.JSONDecodeError as e:
            error_msg = f"Invalid notebook format in {notebook_path}: {e}"
            logger.error(error_msg)
            raise NotebookProcessingError(error_msg) from e
        except Exception as e:
            error_msg = f"Error processing notebook {notebook_path}: {e}"
            logger.error(error_msg)
            raise NotebookProcessingError(error_msg) from e

    @staticmethod
    def to_script(notebook_path: Path) -> str:
        """Convert notebook to Python script (synchronous wrapper)."""
        import asyncio

        try:
            return asyncio.run(NotebookConverter.to_script_async(notebook_path))
        except NotebookProcessingError as e:
            logger.error(f"Error in to_script: {e}")
            return f"# Error processing notebook: {e}"
        except Exception as e:
            logger.error(f"Unexpected error in to_script: {e}")
            return f"# Unexpected error processing notebook: {e}"



================================================
File: src/the_aichemist_codex/backend/project_reader/tags.py
================================================
# src/project_reader/tags.py


class Tag:
    def __init__(self, name: str):
        self.name = name

    def __repr__(self):
        return f"Tag({self.name})"


def parse_tag(tag_str: str):
    """Parses a tag string into a Tag object"""
    return Tag(tag_str.strip())



================================================
File: src/the_aichemist_codex/backend/project_reader/token_counter.py
================================================
import tiktoken


class TokenAnalyzer:
    def __init__(self):
        self.encoder = tiktoken.get_encoding("cl100k_base")

    def estimate(self, text: str) -> int:
        return len(self.encoder.encode(text))



================================================
File: src/the_aichemist_codex/backend/project_reader/version.py
================================================
# src/project_reader/version.py


class InvalidVersion(Exception):
    """Raised when an invalid version string is encountered."""

    pass


class Version:
    def __init__(self, version_str: str):
        if not version_str:
            raise InvalidVersion("Version string cannot be empty.")
        self.version_str = version_str

    def __repr__(self):
        return f"Version({self.version_str})"
